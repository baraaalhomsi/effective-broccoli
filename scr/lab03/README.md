# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3 - –¢–µ–∫—Å—Ç—ã –∏ —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤

## –û–ø–∏—Å–∞–Ω–∏–µ
–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ —á–∞—Å—Ç–æ—Ç —Å–ª–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞.

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
src/
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îî‚îÄ‚îÄ text.py           # –ú–æ–¥—É–ª—å —Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º
‚îî‚îÄ‚îÄ lab03/
    ‚îú‚îÄ‚îÄ text_stats.py      # –°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞ –∏–∑ stdin
    ‚îî‚îÄ‚îÄ README.md          # –≠—Ç–æ—Ç —Ñ–∞–π–ª
```

### –∑–∞–¥–∞–Ω–∏e A
```python
import re
from typing import Dict, List, Tuple

def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:

    if not text:
        return ""

    if casefold:
        text = text.casefold()

    if yo2e:
        text = text.replace('—ë', '–µ')
        text = text.replace('–Å', '–ï')

    control_chars = ['\t', '\r', '\n', '\v', '\f']
    for char in control_chars:
        text = text.replace(char, ' ')

    text = re.sub(r'\s+', ' ', text)
    text = text.strip()
    
    return text

def tokenize(text: str) -> List[str]:

    if not text:
        return []

    pattern = r'[\w]+(?:-[\w]+)*'
    
    tokens = re.findall(pattern, text)
    return tokens

def count_freq(tokens: List[str]) -> Dict[str, int]:

    freq_dict = {}
    for token in tokens:
        freq_dict[token] = freq_dict.get(token, 0) + 1
    return freq_dict

def top_n(freq: Dict[str, int], n: int = 5) -> List[Tuple[str, int]]:

    items = list(freq.items())

    items.sort(key=lambda x: (-x[1], x[0]))
    
    return items[:n]
if __name__ == "__main__":
    print("===normalize===")
    print(normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–∏—Ä\t"))
    print(normalize("—ë–∂–∏–∫, –Å–ª–∫–∞"))
    print(normalize("Hello\r\nWorld"))
    print(normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ",),"\n")

    print("===tokenizee===")
    print(tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"))
    print(tokenize("hello,world!!!"))
    print(tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"))
    print(tokenize("2025 –≥–æ–¥"))
    print(tokenize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"),"\n")

    print("===count_freq + top_n===")
    freq=count_freq(["a","b","a","c","b","a"])
    print(freq)
    print(top_n(freq, n=2))
    freq2=count_freq(["bb","aa","bb","aa","cc"])
    print(freq2)
    print(top_n(freq2, n=2),"\n")
```

![alt text](/images/lab03/A.png)

### –∑–∞–¥–∞–Ω–∏e B
```python
import sys
import os

sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'lib'))

from text import normalize, tokenize, count_freq, top_n

def process_text(text: str, table_output: bool = False) -> str:

    if not text.strip():
        return "No input text provided."

    normalized_text = normalize(text)
    tokens = tokenize(normalized_text)
    frequencies = count_freq(tokens)
    top_words = top_n(frequencies, 5)

    output_lines = []
    output_lines.append(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}")
    output_lines.append(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(frequencies)}")
    output_lines.append("–¢–æ–ø-5:")
    
    if table_output:

        if top_words:
            
            max_word_len = max(len(word) for word, _ in top_words)
            max_word_len = max(max_word_len, len("—Å–ª–æ–≤–æ"))
            
            header_word = "—Å–ª–æ–≤–æ".ljust(max_word_len)
            output_lines.append(f"| {header_word} | —á–∞—Å—Ç–æ—Ç–∞ |")
            output_lines.append(f"|{'-' * (max_word_len + 2)}|---------|")

            for word, freq in top_words:
                padded_word = word.ljust(max_word_len)
                output_lines.append(f"| {padded_word} | {freq:7} |")
        else:
            output_lines.append("| (–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö) |         |")
    else:
        
        for word, freq in top_words:
            output_lines.append(f"{word}:{freq}")
    
    return "\n".join(output_lines)

def main():

    table_output = os.getenv('TEXT_STATS_TABLE', '0') == '1'

    if '--table' in sys.argv or '-t' in sys.argv:
        table_output = True

    if sys.stdin.isatty():
        
        print("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç (Ctrl+Z –∑–∞—Ç–µ–º Enter –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤–≤–æ–¥–∞ –Ω–∞ Windows):")
        print("–î–ª—è —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ: --table –∏–ª–∏ -t")
    
    try:
        input_text = sys.stdin.read().strip()
    except KeyboardInterrupt:
        print("\n–í–≤–æ–¥ –ø—Ä–µ—Ä–≤–∞–Ω.")
        return
    
    if not input_text:
        print("–û—à–∏–±–∫–∞: –ù–µ –ø–æ–ª—É—á–µ–Ω –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç.")
        sys.exit(1)

    result = process_text(input_text, table_output)
    print(result)

if __name__ == "__main__":
    main()
```

![alt text](/images/lab03/B.png)